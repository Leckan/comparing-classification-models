{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing Classification Models\n",
    "\n",
    "We want to compare various classification models for the \"default\" dataset. We'll look at logistic regression, LDA, QDA, $k$-nearest neighbors, and all the different trees we tried."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# We'll look at logistic regression, LDA, QDA, and KNN\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# We'll standardize and split data into training/testing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Need to measure \"goodness\"\n",
    "from sklearn.metrics import accuracy_score, recall_score, average_precision_score, precision_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score, plot_roc_curve, plot_precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 4)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the data from the .csv file\n",
    "default = pd.read_csv(\"default.csv\")\n",
    "default.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 4 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   default  10000 non-null  object \n",
      " 1   student  10000 non-null  object \n",
      " 2   balance  10000 non-null  float64\n",
      " 3   income   10000 non-null  float64\n",
      "dtypes: float64(2), object(2)\n",
      "memory usage: 312.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# Take a look at info()\n",
    "default.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>balance</th>\n",
       "      <th>income</th>\n",
       "      <th>default_Yes</th>\n",
       "      <th>student_Yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7677</th>\n",
       "      <td>65.332984</td>\n",
       "      <td>31992.242221</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1911</th>\n",
       "      <td>605.365694</td>\n",
       "      <td>39002.229643</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2988</th>\n",
       "      <td>634.217926</td>\n",
       "      <td>38672.749647</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>1060.335860</td>\n",
       "      <td>56607.253973</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8490</th>\n",
       "      <td>663.610199</td>\n",
       "      <td>48089.520547</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3330</th>\n",
       "      <td>1335.131324</td>\n",
       "      <td>17044.365397</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7784</th>\n",
       "      <td>2040.590171</td>\n",
       "      <td>50930.910786</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4797</th>\n",
       "      <td>570.024684</td>\n",
       "      <td>40987.062331</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9822</th>\n",
       "      <td>1609.136059</td>\n",
       "      <td>16373.945359</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9989</th>\n",
       "      <td>999.281112</td>\n",
       "      <td>20013.350644</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5734</th>\n",
       "      <td>865.697004</td>\n",
       "      <td>33541.046380</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          balance        income  default_Yes  student_Yes\n",
       "7677    65.332984  31992.242221            0            0\n",
       "1911   605.365694  39002.229643            0            0\n",
       "2988   634.217926  38672.749647            0            0\n",
       "716   1060.335860  56607.253973            0            0\n",
       "8490   663.610199  48089.520547            0            0\n",
       "3330  1335.131324  17044.365397            0            1\n",
       "7784  2040.590171  50930.910786            1            0\n",
       "4797   570.024684  40987.062331            0            0\n",
       "9822  1609.136059  16373.945359            0            1\n",
       "9989   999.281112  20013.350644            0            1\n",
       "5734   865.697004  33541.046380            0            0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dummies for default and student\n",
    "defaultCoded = pd.get_dummies(default, drop_first=True)\n",
    "defaultCoded.sample(11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stratification\n",
    "In many cases, particularly when you an **imbalanced** dataset, you want your training and test sets to preserve the same proportions of each class (i.e., the thing you are trying to predict) as observed in the original dataset. In our case, we would like to have the training and test set each have 3.33% defaulters. We can split our data using **stratification**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>balance</th>\n",
       "      <th>student_Yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>729.526495</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>817.180407</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1073.549164</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>529.250605</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>785.655883</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       balance  student_Yes\n",
       "0   729.526495            0\n",
       "1   817.180407            1\n",
       "2  1073.549164            0\n",
       "3   529.250605            0\n",
       "4   785.655883            0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make the X and y variables\n",
    "# From last time, we saw that income was not statistically significant\n",
    "#     so let's also drop that column\n",
    "y = defaultCoded.default_Yes\n",
    "X = defaultCoded.drop(columns=[\"default_Yes\", \"income\"])\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,\n",
    "                                                    stratify=y,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training default rate is 3.33%\n",
      "Testing default rate is  3.33%\n"
     ]
    }
   ],
   "source": [
    "# What is the default rates in both training and test??\n",
    "print(f\"Training default rate is {y_train.mean():.2%}\")\n",
    "print(f\"Testing default rate is  {y_test.mean():.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to Look at Different Models\n",
    "Can we write a function that will take in different models (classifiers) and compute the different metrics so we can compare the different classifiers easily?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define our function\n",
    "def modelMetrics(classifier, name, X_test, y_test):\n",
    "    \"\"\"\n",
    "    We want to see how the different models react to the same \n",
    "    dataset. We should capture multiple metrics for each model.\n",
    "    \n",
    "    classifier: the classifier we are capturing metrics for\n",
    "    \n",
    "    name: a name to identify the classifier\n",
    "    \n",
    "    X_test: the X array for the test set\n",
    "    \n",
    "    y_test: the output variable (actual) for test set\n",
    "    \"\"\"\n",
    "    retVal = {}\n",
    "    \n",
    "    metrics = {}\n",
    "    predictions = classifier.predict(X_test)\n",
    "    metrics[\"a_score\"] = accuracy_score(y_test, predictions)\n",
    "    metrics[\"r_score\"] = recall_score(y_test, predictions)\n",
    "    metrics[\"p_score\"] = precision_score(y_test, predictions)\n",
    "    metrics[\"f1_score\"] = f1_score(y_test, predictions)\n",
    "    \n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, predictions).ravel()\n",
    "    totDefaulters = y_test.sum()\n",
    "    totNonDefaulters = len(y_test) - totDefaulters\n",
    "    \n",
    "    # Error rate non-defaulters = false positives / total non-defaulters\n",
    "    metrics[\"errorNondefaulters\"] = fp/totNonDefaulters\n",
    "    # Accuracy for non-defaulters = true negatives / total non-defaulters\n",
    "    metrics[\"accNondefaulters\"] = tn/totNonDefaulters\n",
    "    # Error rate for defaulters = false negatives / total defaulters\n",
    "    metrics[\"errorDefaulters\"] = fn/totDefaulters\n",
    "    # Accuracy for defaulters = true positives / total defaulters\n",
    "    metrics[\"accDefaulters\"] = tp/totDefaulters\n",
    "    # ROC AUC score\n",
    "    metrics[\"roc_auc_score\"] = roc_auc_score(y_test,\n",
    "                                             classifier.predict_proba(X_test)[:,1])\n",
    "    # Average precision score\n",
    "    metrics[\"avg_p_score\"] = average_precision_score(y_test,\n",
    "                                                     classifier.predict_proba(X_test)[:,1])\n",
    "    \n",
    "    retVal[name] = metrics\n",
    "    \n",
    "    return retVal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n",
    "We'll use `StandardScaler` to standardize the $X$ variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the StandardScaler and fit\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "# Scale training and test Xs\n",
    "X_train_s = scaler.transform(X_train)\n",
    "X_test_s = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First, create the LogisticRegression instance\n",
    "logReg = LogisticRegression()\n",
    "# Now fit the logistic regression model with the scaled X and unscaled y\n",
    "logReg.fit(X_train_s, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LogisticRegression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a_score</th>\n",
       "      <td>0.972333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accDefaulters</th>\n",
       "      <td>0.330000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accNondefaulters</th>\n",
       "      <td>0.994483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_p_score</th>\n",
       "      <td>0.503314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>errorDefaulters</th>\n",
       "      <td>0.670000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>errorNondefaulters</th>\n",
       "      <td>0.005517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score</th>\n",
       "      <td>0.442953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p_score</th>\n",
       "      <td>0.673469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r_score</th>\n",
       "      <td>0.330000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc_score</th>\n",
       "      <td>0.951041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    LogisticRegression\n",
       "a_score                       0.972333\n",
       "accDefaulters                 0.330000\n",
       "accNondefaulters              0.994483\n",
       "avg_p_score                   0.503314\n",
       "errorDefaulters               0.670000\n",
       "errorNondefaulters            0.005517\n",
       "f1_score                      0.442953\n",
       "p_score                       0.673469\n",
       "r_score                       0.330000\n",
       "roc_auc_score                 0.951041"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call our function to get metrics - let's also put it in DataFrame\n",
    "dfLogReg = pd.DataFrame(modelMetrics(logReg,\"LogisticRegression\",X_test_s, y_test))\n",
    "dfLogReg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Discriminant Analysis\n",
    "Let's now try LDA. We already imported the appropriate packages for LDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearDiscriminantAnalysis()"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an LDA instance\n",
    "lda = LDA()\n",
    "# Fit the LDA model with X and y training set created previously\n",
    "lda.fit(X_train_s, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LDA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a_score</th>\n",
       "      <td>0.971333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accDefaulters</th>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accNondefaulters</th>\n",
       "      <td>0.996207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_p_score</th>\n",
       "      <td>0.502443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>errorDefaulters</th>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>errorNondefaulters</th>\n",
       "      <td>0.003793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score</th>\n",
       "      <td>0.367647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p_score</th>\n",
       "      <td>0.694444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r_score</th>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc_score</th>\n",
       "      <td>0.950731</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         LDA\n",
       "a_score             0.971333\n",
       "accDefaulters       0.250000\n",
       "accNondefaulters    0.996207\n",
       "avg_p_score         0.502443\n",
       "errorDefaulters     0.750000\n",
       "errorNondefaulters  0.003793\n",
       "f1_score            0.367647\n",
       "p_score             0.694444\n",
       "r_score             0.250000\n",
       "roc_auc_score       0.950731"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call our function to get metrics - let's also put it in DataFrame\n",
    "dfLDA = pd.DataFrame(modelMetrics(lda,\"LDA\",X_test_s, y_test))\n",
    "dfLDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quadratic Discriminant Analysis\n",
    "We can also try QDA (already imported package)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QuadraticDiscriminantAnalysis()"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a QDA instance\n",
    "qda = QuadraticDiscriminantAnalysis()\n",
    "# Fit the qda with X and y\n",
    "qda.fit(X_train_s, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QuadraticDiscriminantAnalysis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a_score</th>\n",
       "      <td>0.972667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accDefaulters</th>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accNondefaulters</th>\n",
       "      <td>0.995862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_p_score</th>\n",
       "      <td>0.496253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>errorDefaulters</th>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>errorNondefaulters</th>\n",
       "      <td>0.004138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score</th>\n",
       "      <td>0.422535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p_score</th>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r_score</th>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc_score</th>\n",
       "      <td>0.950645</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    QuadraticDiscriminantAnalysis\n",
       "a_score                                  0.972667\n",
       "accDefaulters                            0.300000\n",
       "accNondefaulters                         0.995862\n",
       "avg_p_score                              0.496253\n",
       "errorDefaulters                          0.700000\n",
       "errorNondefaulters                       0.004138\n",
       "f1_score                                 0.422535\n",
       "p_score                                  0.714286\n",
       "r_score                                  0.300000\n",
       "roc_auc_score                            0.950645"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call our function to get metrics - let's also put it in DataFrame\n",
    "dfQDA = pd.DataFrame(modelMetrics(qda, \"QuadraticDiscriminantAnalysis\",X_test_s, y_test))\n",
    "dfQDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN\n",
    "Might as well try $k$-nearest neighbors. You pick $k$, so it will be your fault not mine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=9)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's use k=9\n",
    "knn = KNeighborsClassifier(n_neighbors=9)\n",
    "# fit the model\n",
    "knn.fit(X_train_s, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KNN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a_score</th>\n",
       "      <td>0.970667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accDefaulters</th>\n",
       "      <td>0.380000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accNondefaulters</th>\n",
       "      <td>0.991034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_p_score</th>\n",
       "      <td>0.361938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>errorDefaulters</th>\n",
       "      <td>0.620000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>errorNondefaulters</th>\n",
       "      <td>0.008966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score</th>\n",
       "      <td>0.463415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p_score</th>\n",
       "      <td>0.593750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r_score</th>\n",
       "      <td>0.380000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc_score</th>\n",
       "      <td>0.858034</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         KNN\n",
       "a_score             0.970667\n",
       "accDefaulters       0.380000\n",
       "accNondefaulters    0.991034\n",
       "avg_p_score         0.361938\n",
       "errorDefaulters     0.620000\n",
       "errorNondefaulters  0.008966\n",
       "f1_score            0.463415\n",
       "p_score             0.593750\n",
       "r_score             0.380000\n",
       "roc_auc_score       0.858034"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call our function to get metrics - let's also put it in DataFrame\n",
    "dfKNN = pd.DataFrame(modelMetrics(knn, \"KNN\",X_test_s, y_test))\n",
    "dfKNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DecisionTreeClassifier\n",
    "Need to import the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# Create the tree\n",
    "dt = DecisionTreeClassifier()\n",
    "# fit the tree on the scaled X training data\n",
    "dt.fit(X_train_s, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a_score</th>\n",
       "      <td>0.954667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accDefaulters</th>\n",
       "      <td>0.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accNondefaulters</th>\n",
       "      <td>0.975517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_p_score</th>\n",
       "      <td>0.137233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>errorDefaulters</th>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>errorNondefaulters</th>\n",
       "      <td>0.024483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score</th>\n",
       "      <td>0.339806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p_score</th>\n",
       "      <td>0.330189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r_score</th>\n",
       "      <td>0.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc_score</th>\n",
       "      <td>0.662759</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    DecisionTreeClassifier\n",
       "a_score                           0.954667\n",
       "accDefaulters                     0.350000\n",
       "accNondefaulters                  0.975517\n",
       "avg_p_score                       0.137233\n",
       "errorDefaulters                   0.650000\n",
       "errorNondefaulters                0.024483\n",
       "f1_score                          0.339806\n",
       "p_score                           0.330189\n",
       "r_score                           0.350000\n",
       "roc_auc_score                     0.662759"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call our function to get metrics - let's also put it in DataFrame\n",
    "dfDTS = pd.DataFrame(modelMetrics(dt, \"DecisionTreeClassifier\",X_test_s, y_test))\n",
    "dfDTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creat a decision tree on UNSCALED X\n",
    "dt2 = DecisionTreeClassifier()\n",
    "dt2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DT-Unscaled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a_score</th>\n",
       "      <td>0.954667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accDefaulters</th>\n",
       "      <td>0.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accNondefaulters</th>\n",
       "      <td>0.975517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_p_score</th>\n",
       "      <td>0.137233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>errorDefaulters</th>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>errorNondefaulters</th>\n",
       "      <td>0.024483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score</th>\n",
       "      <td>0.339806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p_score</th>\n",
       "      <td>0.330189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r_score</th>\n",
       "      <td>0.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc_score</th>\n",
       "      <td>0.662759</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    DT-Unscaled\n",
       "a_score                0.954667\n",
       "accDefaulters          0.350000\n",
       "accNondefaulters       0.975517\n",
       "avg_p_score            0.137233\n",
       "errorDefaulters        0.650000\n",
       "errorNondefaulters     0.024483\n",
       "f1_score               0.339806\n",
       "p_score                0.330189\n",
       "r_score                0.350000\n",
       "roc_auc_score          0.662759"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call our function to get metrics - let's also put it in DataFrame\n",
    "dfDTUS = pd.DataFrame(modelMetrics(dt2, \"DT-Unscaled\",X_test, y_test))\n",
    "dfDTUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=6, random_state=42)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try a different max_depth\n",
    "dt3 = DecisionTreeClassifier(max_depth =6, random_state=42)\n",
    "dt3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DT-Depth_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a_score</th>\n",
       "      <td>0.968000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accDefaulters</th>\n",
       "      <td>0.310000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accNondefaulters</th>\n",
       "      <td>0.990690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_p_score</th>\n",
       "      <td>0.381994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>errorDefaulters</th>\n",
       "      <td>0.690000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>errorNondefaulters</th>\n",
       "      <td>0.009310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score</th>\n",
       "      <td>0.392405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p_score</th>\n",
       "      <td>0.534483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r_score</th>\n",
       "      <td>0.310000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc_score</th>\n",
       "      <td>0.876579</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    DT-Depth_6\n",
       "a_score               0.968000\n",
       "accDefaulters         0.310000\n",
       "accNondefaulters      0.990690\n",
       "avg_p_score           0.381994\n",
       "errorDefaulters       0.690000\n",
       "errorNondefaulters    0.009310\n",
       "f1_score              0.392405\n",
       "p_score               0.534483\n",
       "r_score               0.310000\n",
       "roc_auc_score         0.876579"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call our function to get metrics - let's also put it in DataFrame\n",
    "dfDT6 = pd.DataFrame(modelMetrics(dt3, \"DT-Depth_6\",X_test, y_test))\n",
    "dfDT6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BaggingClassifier\n",
    "Need to import."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier()"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a bag\n",
    "bag = BaggingClassifier()\n",
    "# Fit it\n",
    "bag.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bagging</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a_score</th>\n",
       "      <td>0.956667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accDefaulters</th>\n",
       "      <td>0.330000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accNondefaulters</th>\n",
       "      <td>0.978276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_p_score</th>\n",
       "      <td>0.284543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>errorDefaulters</th>\n",
       "      <td>0.670000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>errorNondefaulters</th>\n",
       "      <td>0.021724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score</th>\n",
       "      <td>0.336735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p_score</th>\n",
       "      <td>0.343750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r_score</th>\n",
       "      <td>0.330000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc_score</th>\n",
       "      <td>0.789898</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Bagging\n",
       "a_score             0.956667\n",
       "accDefaulters       0.330000\n",
       "accNondefaulters    0.978276\n",
       "avg_p_score         0.284543\n",
       "errorDefaulters     0.670000\n",
       "errorNondefaulters  0.021724\n",
       "f1_score            0.336735\n",
       "p_score             0.343750\n",
       "r_score             0.330000\n",
       "roc_auc_score       0.789898"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call our function to get metrics - let's also put it in DataFrame\n",
    "dfBag = pd.DataFrame(modelMetrics(bag, \"Bagging\",X_test, y_test))\n",
    "dfBag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForestClassifier\n",
    "Need to import."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create random forest\n",
    "rf = RandomForestClassifier()\n",
    "# fit it\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RandomForest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a_score</th>\n",
       "      <td>0.954000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accDefaulters</th>\n",
       "      <td>0.360000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accNondefaulters</th>\n",
       "      <td>0.974483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_p_score</th>\n",
       "      <td>0.317787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>errorDefaulters</th>\n",
       "      <td>0.640000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>errorNondefaulters</th>\n",
       "      <td>0.025517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score</th>\n",
       "      <td>0.342857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p_score</th>\n",
       "      <td>0.327273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r_score</th>\n",
       "      <td>0.360000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc_score</th>\n",
       "      <td>0.820909</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    RandomForest\n",
       "a_score                 0.954000\n",
       "accDefaulters           0.360000\n",
       "accNondefaulters        0.974483\n",
       "avg_p_score             0.317787\n",
       "errorDefaulters         0.640000\n",
       "errorNondefaulters      0.025517\n",
       "f1_score                0.342857\n",
       "p_score                 0.327273\n",
       "r_score                 0.360000\n",
       "roc_auc_score           0.820909"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call our function to get metrics - let's also put it in DataFrame\n",
    "dfRf = pd.DataFrame(modelMetrics(rf, \"RandomForest\",X_test, y_test))\n",
    "dfRf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extremely Randomized Trees\n",
    "Need to import."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier()"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create it\n",
    "xtc = ExtraTreesClassifier()\n",
    "# Fit it\n",
    "xtc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Extra Trees</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a_score</th>\n",
       "      <td>0.954667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accDefaulters</th>\n",
       "      <td>0.380000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accNondefaulters</th>\n",
       "      <td>0.974483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_p_score</th>\n",
       "      <td>0.239061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>errorDefaulters</th>\n",
       "      <td>0.620000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>errorNondefaulters</th>\n",
       "      <td>0.025517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score</th>\n",
       "      <td>0.358491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p_score</th>\n",
       "      <td>0.339286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r_score</th>\n",
       "      <td>0.380000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc_score</th>\n",
       "      <td>0.747143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Extra Trees\n",
       "a_score                0.954667\n",
       "accDefaulters          0.380000\n",
       "accNondefaulters       0.974483\n",
       "avg_p_score            0.239061\n",
       "errorDefaulters        0.620000\n",
       "errorNondefaulters     0.025517\n",
       "f1_score               0.358491\n",
       "p_score                0.339286\n",
       "r_score                0.380000\n",
       "roc_auc_score          0.747143"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call our function to get metrics - let's also put it in DataFrame\n",
    "dfXTC = pd.DataFrame(modelMetrics(xtc, \"Extra Trees\",X_test, y_test))\n",
    "dfXTC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost\n",
    "Need to import."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier()"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create it\n",
    "ada = AdaBoostClassifier()\n",
    "# fit it\n",
    "ada.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ADA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a_score</th>\n",
       "      <td>0.970333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accDefaulters</th>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accNondefaulters</th>\n",
       "      <td>0.990000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_p_score</th>\n",
       "      <td>0.438557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>errorDefaulters</th>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>errorNondefaulters</th>\n",
       "      <td>0.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score</th>\n",
       "      <td>0.473373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p_score</th>\n",
       "      <td>0.579710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r_score</th>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc_score</th>\n",
       "      <td>0.951383</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         ADA\n",
       "a_score             0.970333\n",
       "accDefaulters       0.400000\n",
       "accNondefaulters    0.990000\n",
       "avg_p_score         0.438557\n",
       "errorDefaulters     0.600000\n",
       "errorNondefaulters  0.010000\n",
       "f1_score            0.473373\n",
       "p_score             0.579710\n",
       "r_score             0.400000\n",
       "roc_auc_score       0.951383"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call our function to get metrics - let's also put it in DataFrame\n",
    "dfAda = pd.DataFrame(modelMetrics(ada, \"ADA\",X_test, y_test))\n",
    "dfAda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting\n",
    "Need to import."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier()"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create it\n",
    "gbc = GradientBoostingClassifier()\n",
    "# fit it\n",
    "gbc.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GradientBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a_score</th>\n",
       "      <td>0.967333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accDefaulters</th>\n",
       "      <td>0.360000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accNondefaulters</th>\n",
       "      <td>0.988276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_p_score</th>\n",
       "      <td>0.395060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>errorDefaulters</th>\n",
       "      <td>0.640000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>errorNondefaulters</th>\n",
       "      <td>0.011724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score</th>\n",
       "      <td>0.423529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p_score</th>\n",
       "      <td>0.514286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r_score</th>\n",
       "      <td>0.360000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc_score</th>\n",
       "      <td>0.946391</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    GradientBoost\n",
       "a_score                  0.967333\n",
       "accDefaulters            0.360000\n",
       "accNondefaulters         0.988276\n",
       "avg_p_score              0.395060\n",
       "errorDefaulters          0.640000\n",
       "errorNondefaulters       0.011724\n",
       "f1_score                 0.423529\n",
       "p_score                  0.514286\n",
       "r_score                  0.360000\n",
       "roc_auc_score            0.946391"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call our function to get metrics - let's also put it in DataFrame\n",
    "dfGbc = pd.DataFrame(modelMetrics(gbc, \"GradientBoost\",X_test, y_test))\n",
    "dfGbc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost\n",
    "Need to import."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:44:26] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leckan/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=8, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create it\n",
    "xgbClf = xgb.XGBClassifier()\n",
    "# fit it\n",
    "xgbClf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a_score</th>\n",
       "      <td>0.968333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accDefaulters</th>\n",
       "      <td>0.340000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accNondefaulters</th>\n",
       "      <td>0.990000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_p_score</th>\n",
       "      <td>0.437857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>errorDefaulters</th>\n",
       "      <td>0.660000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>errorNondefaulters</th>\n",
       "      <td>0.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score</th>\n",
       "      <td>0.417178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p_score</th>\n",
       "      <td>0.539683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r_score</th>\n",
       "      <td>0.340000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc_score</th>\n",
       "      <td>0.943986</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     XGBoost\n",
       "a_score             0.968333\n",
       "accDefaulters       0.340000\n",
       "accNondefaulters    0.990000\n",
       "avg_p_score         0.437857\n",
       "errorDefaulters     0.660000\n",
       "errorNondefaulters  0.010000\n",
       "f1_score            0.417178\n",
       "p_score             0.539683\n",
       "r_score             0.340000\n",
       "roc_auc_score       0.943986"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call our function to get metrics - let's also put it in DataFrame\n",
    "dfXGB = pd.DataFrame(modelMetrics(xgbClf, \"XGBoost\",X_test, y_test))\n",
    "dfXGB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at All Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a list called allDfs that contains all the DataFrames\n",
    "# we created that contain the model metrics\n",
    "allDfs = [dfLogReg, dfLDA, dfQDA, dfKNN, dfDTS, dfDTUS, dfDT6, dfBag, dfRf, dfXTC, dfAda, dfGbc, dfXGB]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LogisticRegression</th>\n",
       "      <th>LDA</th>\n",
       "      <th>QuadraticDiscriminantAnalysis</th>\n",
       "      <th>KNN</th>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <th>DT-Unscaled</th>\n",
       "      <th>DT-Depth_6</th>\n",
       "      <th>Bagging</th>\n",
       "      <th>RandomForest</th>\n",
       "      <th>Extra Trees</th>\n",
       "      <th>ADA</th>\n",
       "      <th>GradientBoost</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a_score</th>\n",
       "      <td>0.972333</td>\n",
       "      <td>0.971333</td>\n",
       "      <td>0.972667</td>\n",
       "      <td>0.970667</td>\n",
       "      <td>0.954667</td>\n",
       "      <td>0.954667</td>\n",
       "      <td>0.968000</td>\n",
       "      <td>0.956667</td>\n",
       "      <td>0.954000</td>\n",
       "      <td>0.954667</td>\n",
       "      <td>0.970333</td>\n",
       "      <td>0.967333</td>\n",
       "      <td>0.968333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accDefaulters</th>\n",
       "      <td>0.330000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.310000</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>0.340000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accNondefaulters</th>\n",
       "      <td>0.994483</td>\n",
       "      <td>0.996207</td>\n",
       "      <td>0.995862</td>\n",
       "      <td>0.991034</td>\n",
       "      <td>0.975517</td>\n",
       "      <td>0.975517</td>\n",
       "      <td>0.990690</td>\n",
       "      <td>0.978276</td>\n",
       "      <td>0.974483</td>\n",
       "      <td>0.974483</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>0.988276</td>\n",
       "      <td>0.990000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_p_score</th>\n",
       "      <td>0.503314</td>\n",
       "      <td>0.502443</td>\n",
       "      <td>0.496253</td>\n",
       "      <td>0.361938</td>\n",
       "      <td>0.137233</td>\n",
       "      <td>0.137233</td>\n",
       "      <td>0.381994</td>\n",
       "      <td>0.284543</td>\n",
       "      <td>0.317787</td>\n",
       "      <td>0.239061</td>\n",
       "      <td>0.438557</td>\n",
       "      <td>0.395060</td>\n",
       "      <td>0.437857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>errorDefaulters</th>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.690000</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.660000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>errorNondefaulters</th>\n",
       "      <td>0.005517</td>\n",
       "      <td>0.003793</td>\n",
       "      <td>0.004138</td>\n",
       "      <td>0.008966</td>\n",
       "      <td>0.024483</td>\n",
       "      <td>0.024483</td>\n",
       "      <td>0.009310</td>\n",
       "      <td>0.021724</td>\n",
       "      <td>0.025517</td>\n",
       "      <td>0.025517</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.011724</td>\n",
       "      <td>0.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score</th>\n",
       "      <td>0.442953</td>\n",
       "      <td>0.367647</td>\n",
       "      <td>0.422535</td>\n",
       "      <td>0.463415</td>\n",
       "      <td>0.339806</td>\n",
       "      <td>0.339806</td>\n",
       "      <td>0.392405</td>\n",
       "      <td>0.336735</td>\n",
       "      <td>0.342857</td>\n",
       "      <td>0.358491</td>\n",
       "      <td>0.473373</td>\n",
       "      <td>0.423529</td>\n",
       "      <td>0.417178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p_score</th>\n",
       "      <td>0.673469</td>\n",
       "      <td>0.694444</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.593750</td>\n",
       "      <td>0.330189</td>\n",
       "      <td>0.330189</td>\n",
       "      <td>0.534483</td>\n",
       "      <td>0.343750</td>\n",
       "      <td>0.327273</td>\n",
       "      <td>0.339286</td>\n",
       "      <td>0.579710</td>\n",
       "      <td>0.514286</td>\n",
       "      <td>0.539683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r_score</th>\n",
       "      <td>0.330000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.310000</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>0.340000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc_score</th>\n",
       "      <td>0.951041</td>\n",
       "      <td>0.950731</td>\n",
       "      <td>0.950645</td>\n",
       "      <td>0.858034</td>\n",
       "      <td>0.662759</td>\n",
       "      <td>0.662759</td>\n",
       "      <td>0.876579</td>\n",
       "      <td>0.789898</td>\n",
       "      <td>0.820909</td>\n",
       "      <td>0.747143</td>\n",
       "      <td>0.951383</td>\n",
       "      <td>0.946391</td>\n",
       "      <td>0.943986</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    LogisticRegression       LDA  \\\n",
       "a_score                       0.972333  0.971333   \n",
       "accDefaulters                 0.330000  0.250000   \n",
       "accNondefaulters              0.994483  0.996207   \n",
       "avg_p_score                   0.503314  0.502443   \n",
       "errorDefaulters               0.670000  0.750000   \n",
       "errorNondefaulters            0.005517  0.003793   \n",
       "f1_score                      0.442953  0.367647   \n",
       "p_score                       0.673469  0.694444   \n",
       "r_score                       0.330000  0.250000   \n",
       "roc_auc_score                 0.951041  0.950731   \n",
       "\n",
       "                    QuadraticDiscriminantAnalysis       KNN  \\\n",
       "a_score                                  0.972667  0.970667   \n",
       "accDefaulters                            0.300000  0.380000   \n",
       "accNondefaulters                         0.995862  0.991034   \n",
       "avg_p_score                              0.496253  0.361938   \n",
       "errorDefaulters                          0.700000  0.620000   \n",
       "errorNondefaulters                       0.004138  0.008966   \n",
       "f1_score                                 0.422535  0.463415   \n",
       "p_score                                  0.714286  0.593750   \n",
       "r_score                                  0.300000  0.380000   \n",
       "roc_auc_score                            0.950645  0.858034   \n",
       "\n",
       "                    DecisionTreeClassifier  DT-Unscaled  DT-Depth_6   Bagging  \\\n",
       "a_score                           0.954667     0.954667    0.968000  0.956667   \n",
       "accDefaulters                     0.350000     0.350000    0.310000  0.330000   \n",
       "accNondefaulters                  0.975517     0.975517    0.990690  0.978276   \n",
       "avg_p_score                       0.137233     0.137233    0.381994  0.284543   \n",
       "errorDefaulters                   0.650000     0.650000    0.690000  0.670000   \n",
       "errorNondefaulters                0.024483     0.024483    0.009310  0.021724   \n",
       "f1_score                          0.339806     0.339806    0.392405  0.336735   \n",
       "p_score                           0.330189     0.330189    0.534483  0.343750   \n",
       "r_score                           0.350000     0.350000    0.310000  0.330000   \n",
       "roc_auc_score                     0.662759     0.662759    0.876579  0.789898   \n",
       "\n",
       "                    RandomForest  Extra Trees       ADA  GradientBoost  \\\n",
       "a_score                 0.954000     0.954667  0.970333       0.967333   \n",
       "accDefaulters           0.360000     0.380000  0.400000       0.360000   \n",
       "accNondefaulters        0.974483     0.974483  0.990000       0.988276   \n",
       "avg_p_score             0.317787     0.239061  0.438557       0.395060   \n",
       "errorDefaulters         0.640000     0.620000  0.600000       0.640000   \n",
       "errorNondefaulters      0.025517     0.025517  0.010000       0.011724   \n",
       "f1_score                0.342857     0.358491  0.473373       0.423529   \n",
       "p_score                 0.327273     0.339286  0.579710       0.514286   \n",
       "r_score                 0.360000     0.380000  0.400000       0.360000   \n",
       "roc_auc_score           0.820909     0.747143  0.951383       0.946391   \n",
       "\n",
       "                     XGBoost  \n",
       "a_score             0.968333  \n",
       "accDefaulters       0.340000  \n",
       "accNondefaulters    0.990000  \n",
       "avg_p_score         0.437857  \n",
       "errorDefaulters     0.660000  \n",
       "errorNondefaulters  0.010000  \n",
       "f1_score            0.417178  \n",
       "p_score             0.539683  \n",
       "r_score             0.340000  \n",
       "roc_auc_score       0.943986  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate all the DataFrames\n",
    "pd.concat(allDfs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import export_graphviz, export_text, plot_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseDT = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.001, 0.002, 0.003, 0.004, 0.005, 0.006, 0.007, 0.008, 0.009,\n",
       "       0.01 , 0.011, 0.012, 0.013, 0.014, 0.015, 0.016, 0.017, 0.018,\n",
       "       0.019, 0.02 , 0.021, 0.022, 0.023, 0.024, 0.025, 0.026, 0.027,\n",
       "       0.028, 0.029, 0.03 , 0.031, 0.032, 0.033, 0.034, 0.035, 0.036,\n",
       "       0.037, 0.038, 0.039, 0.04 , 0.041, 0.042, 0.043, 0.044, 0.045,\n",
       "       0.046, 0.047, 0.048, 0.049, 0.05 , 0.051, 0.052, 0.053, 0.054,\n",
       "       0.055, 0.056, 0.057, 0.058, 0.059, 0.06 , 0.061, 0.062, 0.063,\n",
       "       0.064, 0.065, 0.066, 0.067, 0.068, 0.069, 0.07 , 0.071, 0.072,\n",
       "       0.073, 0.074, 0.075, 0.076, 0.077, 0.078, 0.079, 0.08 , 0.081,\n",
       "       0.082, 0.083, 0.084, 0.085, 0.086, 0.087, 0.088, 0.089, 0.09 ,\n",
       "       0.091, 0.092, 0.093, 0.094, 0.095, 0.096, 0.097, 0.098, 0.099])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ccps= np.arange(0.001,0.1,0.001)\n",
    "ccps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GridSearchCV(baseDT, {'ccp_alpha':ccps}, scoring =\"recall\", verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 99 candidates, totalling 495 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=DecisionTreeClassifier(),\n",
       "             param_grid={'ccp_alpha': array([0.001, 0.002, 0.003, 0.004, 0.005, 0.006, 0.007, 0.008, 0.009,\n",
       "       0.01 , 0.011, 0.012, 0.013, 0.014, 0.015, 0.016, 0.017, 0.018,\n",
       "       0.019, 0.02 , 0.021, 0.022, 0.023, 0.024, 0.025, 0.026, 0.027,\n",
       "       0.028, 0.029, 0.03 , 0.031, 0.032, 0.033, 0.034, 0.035, 0.036,\n",
       "       0.037, 0.038, 0.039, 0.04 , 0.041, 0.042, 0.043, 0.044, 0.045,\n",
       "       0.046, 0.047, 0.048, 0.049, 0.05 , 0.051, 0.052, 0.053, 0.054,\n",
       "       0.055, 0.056, 0.057, 0.058, 0.059, 0.06 , 0.061, 0.062, 0.063,\n",
       "       0.064, 0.065, 0.066, 0.067, 0.068, 0.069, 0.07 , 0.071, 0.072,\n",
       "       0.073, 0.074, 0.075, 0.076, 0.077, 0.078, 0.079, 0.08 , 0.081,\n",
       "       0.082, 0.083, 0.084, 0.085, 0.086, 0.087, 0.088, 0.089, 0.09 ,\n",
       "       0.091, 0.092, 0.093, 0.094, 0.095, 0.096, 0.097, 0.098, 0.099])},\n",
       "             scoring='recall', verbose=1)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49380203515263643"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ccp_alpha': 0.003}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.003, random_state=42)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestDt = DecisionTreeClassifier(ccp_alpha = clf.best_params_[\"ccp_alpha\"],random_state=42)\n",
    "bestDt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.98      0.98      0.98      2900\n",
      "         Yes       0.52      0.48      0.50       100\n",
      "\n",
      "    accuracy                           0.97      3000\n",
      "   macro avg       0.75      0.73      0.74      3000\n",
      "weighted avg       0.97      0.97      0.97      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, bestDt.predict(X_test), target_names=[\"No\",\"Yes\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(167.4, 163.07999999999998, 'balance <= 1800.002\\ngini = 0.064\\nsamples = 7000\\nvalue = [6767, 233]'),\n",
       " Text(83.7, 54.360000000000014, 'gini = 0.034\\nsamples = 6805\\nvalue = [6686, 119]'),\n",
       " Text(251.10000000000002, 54.360000000000014, 'gini = 0.486\\nsamples = 195\\nvalue = [81, 114]')]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_tree(bestDt, feature_names=X.columns, filled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
